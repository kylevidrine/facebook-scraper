#!/bin/bash

# Facebook Event Scraper Deploy Script
# Commits changes to GitHub and rebuilds Docker container

echo "ğŸµ Deploying Facebook Event Scraper..."

# Change to project directory (update this path for your setup)
PROJECT_DIR=${PROJECT_DIR:-$(pwd)}
cd "$PROJECT_DIR" || { echo "âŒ Project folder not found: $PROJECT_DIR"; exit 1; }

echo "ğŸ“ Current directory: $(pwd)"

# Check if .env file exists
if [ ! -f .env ]; then
    echo "âš ï¸  Warning: .env file not found. Creating from example..."
    if [ -f .env.example ]; then
        cp .env.example .env
        echo "ğŸ“‹ Please edit .env file with your configuration before running the scraper"
    else
        echo "âŒ No .env.example file found. Please create .env manually."
        exit 1
    fi
fi

# Check Git status
echo "ğŸ“Š Checking Git status..."
git status

# Add all changes (excluding .env files due to .gitignore)
echo "â• Adding changes to Git..."
git add .

# Check if there are changes to commit
if git diff --staged --quiet; then
    echo "â„¹ï¸  No changes to commit"
else
    # Commit with timestamp
    TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')
    echo "ğŸ’¾ Committing changes..."
    git commit -m "Auto commit: Facebook scraper updates - $TIMESTAMP"
    
    # Push to GitHub
    echo "ğŸš€ Pushing to GitHub..."
    git push origin main || git push origin master || { echo "âŒ Git push failed"; exit 1; }
    echo "âœ… Successfully pushed to GitHub"
fi

# Rebuild and restart Docker container
echo "ğŸ³ Rebuilding Docker container..."
sudo docker-compose down

echo "ğŸ”¨ Building new image with latest changes..."
sudo docker-compose up -d --build

# Wait a moment for container to start
sleep 3

# Check if container is running
if sudo docker ps | grep -q facebook-scraper; then
    echo "âœ… Container is running successfully"
    echo "ğŸ§ª Testing scraper (optional)..."
    echo "Run this command to test: sudo docker exec -it facebook-scraper python scraper.py"
else
    echo "âŒ Container failed to start"
    echo "Check logs with: sudo docker-compose logs facebook-scraper"
fi

echo "ğŸ‰ Deployment complete!"
echo ""
echo "ğŸ“‹ Next steps:"
echo "   â€¢ Test scraper: sudo docker exec -it facebook-scraper python scraper.py"
echo "   â€¢ Check logs: sudo docker-compose logs -f facebook-scraper"
echo "   â€¢ Edit config: nano .env"
echo ""
echo "ğŸ“Š Monitor your events at your N8N webhook endpoint"